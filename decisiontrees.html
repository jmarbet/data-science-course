<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Data Science - 3&nbsp; Decision Trees</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./neuralnetworks.html" rel="next">
<link href="./basics.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./intro.html">Overview and Methods</a></li><li class="breadcrumb-item"><a href="./decisiontrees.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Decision Trees</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science</a> 
        <div class="sidebar-tools-main">
    <a href="./Data-Science.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About this Course</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Overview and Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Basic Concepts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./decisiontrees.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Decision Trees</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./neuralnetworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./additional.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Additional Methods</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Applications</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./applicationI.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Loan Default Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./applicationII.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">House Price Prediction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#what-is-a-decision-tree" id="toc-what-is-a-decision-tree" class="nav-link active" data-scroll-target="#what-is-a-decision-tree"><span class="header-section-number">3.1</span> What is a Decision Tree?</a></li>
  <li><a href="#terminology" id="toc-terminology" class="nav-link" data-scroll-target="#terminology"><span class="header-section-number">3.2</span> Terminology</a></li>
  <li><a href="#how-to-grow-a-tree" id="toc-how-to-grow-a-tree" class="nav-link" data-scroll-target="#how-to-grow-a-tree"><span class="header-section-number">3.3</span> How To Grow a Tree</a>
  <ul class="collapse">
  <li><a href="#example-classification-problem" id="toc-example-classification-problem" class="nav-link" data-scroll-target="#example-classification-problem"><span class="header-section-number">3.3.1</span> Example: Classification Problem</a></li>
  <li><a href="#stopping-criteria-and-pruning-a-tree" id="toc-stopping-criteria-and-pruning-a-tree" class="nav-link" data-scroll-target="#stopping-criteria-and-pruning-a-tree"><span class="header-section-number">3.3.2</span> Stopping Criteria and Pruning a Tree</a></li>
  </ul></li>
  <li><a href="#advantages-and-disadvantages" id="toc-advantages-and-disadvantages" class="nav-link" data-scroll-target="#advantages-and-disadvantages"><span class="header-section-number">3.4</span> Advantages and Disadvantages</a></li>
  <li><a href="#random-forests" id="toc-random-forests" class="nav-link" data-scroll-target="#random-forests"><span class="header-section-number">3.5</span> Random Forests</a></li>
  <li><a href="#boosting" id="toc-boosting" class="nav-link" data-scroll-target="#boosting"><span class="header-section-number">3.6</span> Boosting</a></li>
  <li><a href="#interpreting-ensemble-methods" id="toc-interpreting-ensemble-methods" class="nav-link" data-scroll-target="#interpreting-ensemble-methods"><span class="header-section-number">3.7</span> Interpreting Ensemble Methods</a></li>
  <li><a href="#python-implementation" id="toc-python-implementation" class="nav-link" data-scroll-target="#python-implementation"><span class="header-section-number">3.8</span> Python Implementation</a></li>
  </ul>
<div class="quarto-other-links"><h2>Other Links</h2><ul><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"><i class="bi bi-link-45deg"></i>Scikit-Learn: Decision Tree Classifier</a></li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html"><i class="bi bi-link-45deg"></i>Scikit-Learn: Decision Tree Regressor</a></li><li><a href="https://xgboost.readthedocs.io/en/stable/python/sklearn_estimator.html"><i class="bi bi-link-45deg"></i>XGBoost</a></li></ul></div><div class="quarto-code-links"><h2>Code Links</h2><ul><li><a href="notebooks/decision_trees.ipynb"><i class="bi bi-file-code"></i>Jupyter Notebook</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./intro.html">Overview and Methods</a></li><li class="breadcrumb-item"><a href="./decisiontrees.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Decision Trees</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Decision Trees</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Now that we have covered some of the basics of machine learning, we can start looking at some of the most popular machine learning algorithms. In this chapter, we will focus on <strong>Decision Trees</strong> and <strong>tree-based ensemble methods</strong> such as <strong>Random Forests</strong> and <strong>(Gradient) Boosted Trees</strong>.</p>
<section id="what-is-a-decision-tree" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="what-is-a-decision-tree"><span class="header-section-number">3.1</span> What is a Decision Tree?</h2>
<p><strong>Decision trees</strong>, also called <strong>Classification and Regression Trees (CART)</strong> are a popular <strong>supervised learning method</strong>. As the name CART suggests, they are <strong>used for both classification and regression</strong> problems. They are simple to understand and interpret, and the process of building a decision tree is intuitive. Decision trees are also the <strong>foundation of more advanced ensemble methods</strong> like Random Forests and Boosting.</p>
<div id="fig-decision-tree" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-decision-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/decision-tree-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-decision-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.1: Classification Tree - Classification of Dogs, Snakes, Fish, and Birds based on their Features
</figcaption>
</figure>
</div>
<p><a href="#fig-decision-tree" class="quarto-xref">Figure&nbsp;<span>3.1</span></a> shows an example of a decision tree for a classification problem, i.e., a <strong>classification tree</strong>. In this case, the decision tree is used to classify animals into four categories: dogs, snakes, fish, and birds. The tree asks a series of questions about the features of the animal (e.g., number of legs, feathers, and habitat) and uses the answers to classify the animal. This means that the tree partitions the feature space into different regions that are associated with a particular class label.</p>
<div id="fig-regression-tree" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-regression-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/decision-tree-regression-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-regression-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.2: Regression Tree - Prediction of <span class="math inline">\(y\)</span> based on <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>
</figcaption>
</figure>
</div>
<p><a href="#fig-regression-tree" class="quarto-xref">Figure&nbsp;<span>3.2</span></a> shows an example of a decision tree for a regression problem, i.e., a <strong>regression tree</strong>. In this case, the decision tree is used to predict some continuous variable <span class="math inline">\(y\)</span> (e.g., a house price) based on features <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> (e.g., number of rooms and size of the property). As <a href="#fig-regression-tree-plot" class="quarto-xref">Figure&nbsp;<span>3.7</span></a> shows, the regression tree partitions the <span class="math inline">\((x_1,x_2)\)</span>-space into different regions that are associated with a predicted value <span class="math inline">\(y\)</span>. Mathematically, the prediction of a regression tree can be expressed as</p>
<p><span class="math display">\[\hat{y} = \sum_{m=1}^{M} c_m \mathbb{1}(x \in R_m)\]</span></p>
<p>where <span class="math inline">\(R_m\)</span> are the regions of the feature space, <span class="math inline">\(c_m\)</span> are the predicted (i.e., average) values in the regions, <span class="math inline">\(\mathbb{1}(x \in R_m)\)</span> is an indicator function that is 1 if <span class="math inline">\(x\)</span> is in region <span class="math inline">\(R_m\)</span> and 0 otherwise, and <span class="math inline">\(M\)</span> is the number of regions.</p>
<div id="fig-regression-tree-plot" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-regression-tree-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>

</div>
<div class="cell quarto-layout-panel" data-layout-ncol="2" data-layout-align="center">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
<figcaption>Regions</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/unnamed-chunk-2-2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
<figcaption>Predictions</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-regression-tree-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.3: Regression Tree - Regions and Predictions of Decision Tree in <a href="#fig-regression-tree" class="quarto-xref">Figure&nbsp;<span>3.2</span></a>
</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Mini-Exercise
</div>
</div>
<div class="callout-body-container callout-body">
<p>Given the decision tree in <a href="#fig-regression-tree" class="quarto-xref">Figure&nbsp;<span>3.2</span></a>, what would be the predicted value of <span class="math inline">\(y\)</span> for the following data points?</p>
<ol type="1">
<li><span class="math inline">\((x_1, x_2) = (1, 1)\)</span></li>
<li><span class="math inline">\((x_1, x_2) = (2, 2)\)</span></li>
<li><span class="math inline">\((x_1, x_2) = (2, 8)\)</span></li>
<li><span class="math inline">\((x_1, x_2) = (10, 4)\)</span></li>
<li><span class="math inline">\((x_1, x_2) = (7, 8)\)</span></li>
</ol>
</div>
</div>
</section>
<section id="terminology" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="terminology"><span class="header-section-number">3.2</span> Terminology</h2>
<div id="fig-decision-tree-terminology" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-decision-tree-terminology-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/decision-tree-terminology-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-decision-tree-terminology-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.4: Decision Tree - Terminology
</figcaption>
</figure>
</div>
<p><a href="#fig-decision-tree-terminology" class="quarto-xref">Figure&nbsp;<span>3.4</span></a> shows some of the terminology that you might encounter in decision trees. The <strong>root node</strong> is the first node in the tree. The root node is split into <strong>decision nodes</strong> (or leaf nodes) based on the values of the features. The decision nodes are further split into decision nodes or <strong>leaf nodes</strong>. The leaf nodes represent the final prediction of the model. A <strong>subtree</strong> or <strong>branch</strong> is a part of the tree that starts at a decision node and ends at a leaf node. The <strong>depth</strong> of a tree is the length of the longest path from the root node to a leaf node.</p>
<p>Furthermore, one can also differentiate between <strong>child</strong> and <strong>parent nodes</strong>. A child node is a node that results from a split (e.g., the first (reading from the top) decision node and leaf node in <a href="#fig-decision-tree-terminology" class="quarto-xref">Figure&nbsp;<span>3.4</span></a> are child nodes of the root node). The parent node is the node that is split to create the child nodes (e.g., the root node in <a href="#fig-decision-tree-terminology" class="quarto-xref">Figure&nbsp;<span>3.4</span></a> is the parent node of the first decision node and leaf node).</p>
</section>
<section id="how-to-grow-a-tree" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="how-to-grow-a-tree"><span class="header-section-number">3.3</span> How To Grow a Tree</h2>
<p>A key question is how to determine the order of variables and thresholds that are used in all the splits of a decision tree. There are different algorithms to grow a decision tree, but the most common one is the <strong>CART algorithm</strong>. The CART algorithm is a <strong>greedy algorithm</strong> that grows the tree in a <strong>top-down</strong> manner. The reason for this algorithm choice is that it is computationally infeasible to consider all possible (fully grown) trees to find the best-performing one. So, the CART algorithm grows the tree in a step-by-step manner choosing the splits in a greedy manner (i.e., choosing the one that performs best at that step). This means that the algorithm does not consider the future consequences of the current split and may not find the optimal tree.</p>
<p>The basic idea is to find a split that minimizes some loss function <span class="math inline">\(Q^s\)</span> and to repeat this recursively for all resulting child nodes. Suppose we start from zero, meaning that we first need to determine the root node. We compute the loss function <span class="math inline">\(Q^s\)</span> for all possible splits <span class="math inline">\(s\)</span> that we can make. This means we need to consider all variables in our dataset (and all split thresholds) and choose the one that minimizes the loss <span class="math inline">\(Q^s\)</span>. We then repeat this process for each of the child nodes, and so on, until we reach a stopping criterion. <a href="#fig-decision-tree-split" class="quarto-xref">Figure&nbsp;<span>3.5</span></a> shows an example of a candidate split.</p>
<div id="fig-decision-tree-split" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-decision-tree-split-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/decision-tree-split-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-decision-tree-split-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.5: Example of Decision Tree Split
</figcaption>
</figure>
</div>
<p>Let <span class="math inline">\(\tau\)</span> denote the index of a leaf node with each leaf node <span class="math inline">\(\tau\)</span> corresponding to a region <span class="math inline">\(R_{\tau}\)</span> with <span class="math inline">\(N_{\tau}\)</span> data points. In the case of a classification problem, the loss function is typically either the <strong>Gini impurity</strong></p>
<p><span class="math display">\[Q^s_{\tau} = \sum_{k=1}^{K} p_{\tau k} (1 - p_{\tau k}) = 1- \sum_{k=1}^K p_{\tau k}^2\]</span></p>
<p>or the <strong>cross-entropy</strong></p>
<p><span class="math display">\[Q^s_{\tau} = -\sum_{k=1}^{K} p_{\tau k} \log(p_{\tau k})\]</span></p>
<p>where <span class="math inline">\(p_{\tau k}\)</span> is the proportion of observations in region <span class="math inline">\(R_{\tau}\)</span> that belong to class <span class="math inline">\(k\)</span> and <span class="math inline">\(K\)</span> is the number of classes. Note that both measures become zero when all observations in the region belong to the same class (i.e., <span class="math inline">\(p_{\tau k} = 1\)</span> or <span class="math inline">\(p_{\tau k} = 0\)</span>). This is the ideal case for a classification problem: we say that the node is <strong>pure</strong>.</p>
<p>In the case of a regression problem, the loss function is typically the <strong>mean squared error (MSE)</strong></p>
<p><span class="math display">\[Q^s_{\tau} = \frac{1}{N_{\tau}} \sum_{i \in R_{\tau}} (y_i - \hat{y}_{\tau})^2\]</span></p>
<p>where <span class="math inline">\(\hat{y}_{\tau}\)</span> is the predicted value of the target variable <span class="math inline">\(y\)</span> in region <span class="math inline">\(R_{\tau}\)</span></p>
<p><span class="math display">\[\hat{y}_{\tau} = \frac{1}{N_{\tau}} \sum_{i \in R_{\tau}} y_i,\]</span></p>
<p>i.e., the average of the target variable in region <span class="math inline">\(R_{\tau}\)</span>.</p>
<p>The <strong>total loss of a split</strong> <span class="math inline">\(Q^s\)</span> is then the weighted sum of the loss functions of the child nodes</p>
<p><span class="math display">\[Q^s = \frac{N_1}{N_1+N_2}Q^s_{1} + \frac{N_2}{N_1+N_2}Q^s_{2}\]</span></p>
<p>where <span class="math inline">\(N_1\)</span> and <span class="math inline">\(N_2\)</span> are the number of data points in the child nodes.</p>
<p>Once we have done this for the root node, we repeat the process for each child node. Then, we repeat it for the child nodes of the child nodes, and so on, until we reach a stopping criterion. The stopping criterion can be, for example, a maximum depth of the tree, a minimum number of data points in a leaf node, or a minimum reduction in the loss function.</p>
<section id="example-classification-problem" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="example-classification-problem"><span class="header-section-number">3.3.1</span> Example: Classification Problem</h3>
<p>Suppose you have the data in <a href="#tbl-decision-tree-classification-example" class="quarto-xref">Table&nbsp;<span>3.1</span></a>. The goal is to predict whether a bank will default based on two features: whether the bank is systemically important and its Common Equity Tier 1 (CET1) ratio (i.e., the ratio of CET1 capital to risk-weighted assets). The CET1 ratio is a measure of a bank’s financial strength.</p>
<div class="cell">
<div id="tbl-decision-tree-classification-example" class="cell quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-decision-tree-classification-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3.1: (Made-up) Data for Classification Problem (Bank Default Prediction)
</figcaption>
<div aria-describedby="tbl-decision-tree-classification-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">Default</th>
<th style="text-align: left;">Systemically Important Bank</th>
<th style="text-align: right;">CET1 Ratio (in %)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Yes</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">8.6</td>
</tr>
<tr class="even">
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">9</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Yes</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">10.6</td>
</tr>
<tr class="even">
<td style="text-align: left;">Yes</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">10.8</td>
</tr>
<tr class="odd">
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">11.2</td>
</tr>
<tr class="even">
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">11.5</td>
</tr>
<tr class="odd">
<td style="text-align: left;">No</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">12.4</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>Given that you only have two features, CET1 Ratio and whether it is a systemically important bank, you only have two possible variables for the root node. However, since CET1 is a continuous variable, there are potentially many thresholds that you could use to split the data. To find this threshold, we need to calculate the <strong>Gini impurity</strong> of each possible split and choose the one that minimizes the impurity.</p>
<div class="cell">
<div id="tbl-decision-tree-classification-example-impurity" class="cell quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-decision-tree-classification-example-impurity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3.2: Gini Impurities for Different CET1 Thresholds
</figcaption>
<div aria-describedby="tbl-decision-tree-classification-example-impurity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">CET1 Ratio Threshold</th>
<th style="text-align: right;">Q₁</th>
<th style="text-align: right;">Q₂</th>
<th style="text-align: right;">Q</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">8.8</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.44</td>
<td style="text-align: right;">0.38</td>
</tr>
<tr class="even">
<td style="text-align: right;">9.8</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.2</td>
<td style="text-align: right;">0.29</td>
</tr>
<tr class="odd">
<td style="text-align: right;">10.7</td>
<td style="text-align: right;">0.44</td>
<td style="text-align: right;">0.38</td>
<td style="text-align: right;">0.4</td>
</tr>
<tr class="even">
<td style="text-align: right;">11</td>
<td style="text-align: right;">0.38</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.21</td>
</tr>
<tr class="odd">
<td style="text-align: right;">11.35</td>
<td style="text-align: right;">0.48</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.34</td>
</tr>
<tr class="even">
<td style="text-align: right;">11.95</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.43</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>According to <a href="#tbl-decision-tree-classification-example-impurity" class="quarto-xref">Table&nbsp;<span>3.2</span></a>, the best split is at a CET1 ratio of 7.0%. The Gini impurity for <span class="math inline">\(\text{CET1}\leq 11\%\)</span> is 0.38, the Gini impurity of <span class="math inline">\(\text{CET1}&gt;11\%\)</span> is 0, and the total impurity is 0.21. However, we could also split based on whether a bank would be systemically important. In this case, the Gini impurity of the split is 0.40. This means that the best split is based on the CET1 ratio. We split the data into two regions: one with a CET1 ratio of 11.0% or less and one with a CET1 ratio of more than 11.0%.</p>
<p>Note that the child node for a CET1 ratio of more than <span class="math inline">\(11.0\%\)</span> is already pure, i.e., all banks in this region are not defaulting. However, the child node for a CET1 ratio of <span class="math inline">\(11.0\%\)</span> or less is not pure meaning that we can do additional splits as shown in <a href="#fig-decision-tree-classification-example" class="quarto-xref">Figure&nbsp;<span>3.6</span></a>. In particular, both, the split at a CET1 ratio of 9.8% and the split based on whether a bank is systemically important yield a Gini impurity of 0.25. We choose the split based on whether a bank is systemically important as the next split, which means we can do the final split based on the CET1 ratio.</p>
<div id="fig-decision-tree-classification-example" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-decision-tree-classification-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/decision-tree-classification-example-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-decision-tree-classification-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.6: Classification Tree for <a href="#tbl-decision-tree-classification-example" class="quarto-xref">Table&nbsp;<span>3.1</span></a>
</figcaption>
</figure>
</div>
</section>
<section id="stopping-criteria-and-pruning-a-tree" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="stopping-criteria-and-pruning-a-tree"><span class="header-section-number">3.3.2</span> Stopping Criteria and Pruning a Tree</h3>
<p>A potential problem with decision trees is that they can <strong>overfit</strong> the training data. In principle, we can get the error down to zero if we just make enough splits. This means that the tree can become too complex and capture noise in the data rather than the underlying relationship. To prevent this, we usually set some early stopping criteria like</p>
<ul>
<li>A maximum depth of the tree,</li>
<li>A minimum number of data points in a leaf node,</li>
<li>A minimum number of data points required in a decision node for a split,</li>
<li>A minimum reduction in the loss function, or</li>
<li>A maximum number of leaf nodes,</li>
</ul>
<p>which will prevent the tree from growing too large and all the nodes from becoming pure. We can also use a combination of these criteria. In the Python applications, we will see how to set some of these stopping criteria.</p>
<p><a href="#fig-regression-tree-plot" class="quarto-xref">Figure&nbsp;<span>3.7</span></a> shows an example of how stopping criteria affect the fit of a decision tree. Note that without any stopping criteria, the tree fits the data perfectly but is likely to overfit. By setting a maximum depth or a minimum number of data points in a leaf node, we can prevent the tree from overfitting the data.</p>
<div id="fig-regression-tree-plot" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-regression-tree-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/unnamed-chunk-5-5.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-regression-tree-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.7: Regression Tree - Effect of Stopping Criteria
</figcaption>
</figure>
</div>
<p>Another way to prevent overfitting is to <strong>prune</strong> the tree, i.e., to remove nodes from the tree according to certain rules. This is done <em>after</em> (not during) growing the tree. One common approach is to use <strong>cost-complexity pruning</strong>. The idea is related to regularization that we have seen before, i.e., we add a term to the loss functions above that penalizes tree complexity. The pruning process is controlled by a hyperparameter <span class="math inline">\(\lambda\)</span> that determines the trade-off between the complexity of the tree and its fit to the training data.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Mini-Exercise
</div>
</div>
<div class="callout-body-container callout-body">
<p>How would the decision tree in <a href="#fig-decision-tree-classification-example" class="quarto-xref">Figure&nbsp;<span>3.6</span></a> look like if</p>
<ol type="1">
<li>we required a minimum of 2 data points in a leaf node?</li>
<li>we required a maximum depth of 2?</li>
<li>we required a maximum depth of 2 and a minimum of 3 data points in a leaf node?</li>
<li>we required a minimum of 3 data points for a split?</li>
<li>we required a minimum of 5 data points for a split?</li>
</ol>
</div>
</div>
</section>
</section>
<section id="advantages-and-disadvantages" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="advantages-and-disadvantages"><span class="header-section-number">3.4</span> Advantages and Disadvantages</h2>
<p>As noted by <span class="citation" data-cites="Murphy2022">Murphy (<a href="references.html#ref-Murphy2022" role="doc-biblioref">2022</a>)</span>, decision trees are popular because of some of the <strong>advantages</strong> they offer</p>
<ul>
<li>Easy to interpret</li>
<li>Can handle mixed discrete and continuous inputs</li>
<li>Insensitive to monotone transformations of the inputs</li>
<li>Automatic variable selection</li>
<li>Relatively robust to outliers</li>
<li>Fast to fit and scale well to large data sets</li>
<li>Can handle missing input features<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></li>
</ul>
<p>Their <strong>disadvantages</strong> include</p>
<ul>
<li>Not very accurate at prediction compared to other kinds of models (note, for example, the piece-wise constant nature of the predictions in regression problems)</li>
<li>They are <strong>unstable</strong>: small changes to the input data can have large effects on the structure of the tree (small changes at the top can affect the rest of the tree)</li>
</ul>
</section>
<section id="random-forests" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="random-forests"><span class="header-section-number">3.5</span> Random Forests</h2>
<p><strong>Decision trees can be unstable</strong> meaning that small changes in the training data can lead to large changes in the tree structure. One way to address this issue is to use <strong>Random Forests</strong>. Random Forests is an <strong>ensemble method</strong>: The idea is to build a <strong>large number of trees</strong> (also called weak learners in this context), each of which is <strong>trained on a random subset of the data</strong>. The predictions of the trees are then averaged in regression tasks or determined through majority voting in the case of classification tasks to make the final prediction. Training multiple trees on random subsets of the data is also called <strong>bagging</strong> (short for <strong>bootstrap aggregating</strong>). Random Forests adds an additional layer of randomness by selecting a random subset of features for each tree. This means that each tree is trained on a different subset of the data and a different subset of features.</p>
<div id="fig-random-forest" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-random-forest-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/random-forest-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-random-forest-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.8: Random Forests - Ensemble of Decision Trees with Majority Decision “It’s a dog!”
</figcaption>
</figure>
</div>
<p>The basic steps of the <strong>Random Forest algorithm</strong> are as follows:</p>
<ol type="1">
<li><strong>Bootstrapping</strong>: Randomly draw <span class="math inline">\(N\)</span> samples with replacement from the training data.</li>
<li><strong>Grow a tree</strong>: For each node of the tree, randomly select <span class="math inline">\(m\)</span> features from the <span class="math inline">\(p\)</span> features in the bootstrap dataset and find the best split based on these <span class="math inline">\(m\)</span> features.</li>
<li><strong>Repeat</strong>: Repeat steps 1 and 2 <span class="math inline">\(B\)</span> times to grow <span class="math inline">\(B\)</span> trees.</li>
<li><strong>Prediction</strong>: To get the prediction for a new data point, average the predictions of all trees in the case of regression or use a majority vote in the case of classification.</li>
</ol>
<p>Note that because we draw samples with replacement, some samples will not be included in the bootstrap sample. These samples are called <strong>out-of-bag (OOB) samples</strong>. The OOB samples can be used to estimate the performance of the model without the need for cross-validation since it is “performed along the way” (<span class="citation" data-cites="Hastie2009">Hastie, Tibshirani, and Friedman (<a href="references.html#ref-Hastie2009" role="doc-biblioref">2009</a>)</span>). The OOB error is almost identical to the error obtained through N-fold cross-validation.</p>
</section>
<section id="boosting" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="boosting"><span class="header-section-number">3.6</span> Boosting</h2>
<p>Another popular ensemble method is <strong>Boosting</strong>. The idea behind boosting is to train a sequence of weak learners (e.g., decision trees), each of which tries to correct the mistakes of the previous one. The predictions of the weak learners are then combined to make the final prediction. Note how this differs from Random Forests where the trees are trained independently of each other in parallel, while here we sequentially train the trees to fix the mistakes of the previous ones. The basic steps can be roughly summarized as follows:</p>
<ol type="1">
<li><strong>Initialize the model</strong>: Construct a base tree with just a root node. In the case of a regression problem, the prediction could be the mean of the target variable. In the case of a classification problem, the prediction could be the log odds of the target variable.</li>
<li><strong>Train a weak learner</strong>: Train a weak learner on the data. The weak learner tries to correct the mistakes of the previous model.</li>
<li><strong>Update the model</strong>: Update the model by adding the weak learner to the model. The added weak learner is weighted by a learning rate <span class="math inline">\(\eta\)</span>.</li>
<li><strong>Repeat</strong>: Repeat steps 2 and 3 until we have grown <span class="math inline">\(B\)</span> trees.</li>
</ol>
<p>XGBoost (eXtreme Gradient Boosting) is a popular implementation of the (gradient) boosting algorithm. It is known for its performance and is widely used in machine learning competitions. The algorithm is based on the idea of gradient boosting, which is a generalization of boosting. We will see how to implement XGBoost in Python but will not go into the details of the algorithm here. Other popular implementations of the boosting algorithm are AdaBoost and LightGBM.</p>
</section>
<section id="interpreting-ensemble-methods" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="interpreting-ensemble-methods"><span class="header-section-number">3.7</span> Interpreting Ensemble Methods</h2>
<p>A downside of using ensemble methods is that you lose the interpretability of a single decision tree. However, there are ways to interpret ensemble methods. One way is to look at the <strong>feature importance</strong>. Feature importance tells you how much each feature contributes to the reduction in the loss function. The idea is that features that are used in splits that lead to a large reduction in the loss function are more important. <span class="citation" data-cites="Murphy2022">Murphy (<a href="references.html#ref-Murphy2022" role="doc-biblioref">2022</a>)</span> shows that the feature importance of feature <span class="math inline">\(k\)</span> is</p>
<p><span class="math display">\[R_k(b)=\sum_{j=1}^{J-1} G_j \mathbb{I}(v_j=k)\]</span></p>
<p>where the sum is over all non-leaf (internal) nodes, <span class="math inline">\(G_j\)</span> is the loss reduction (gain) at node <span class="math inline">\(j\)</span>, and <span class="math inline">\(v_j = k\)</span> if node <span class="math inline">\(j\)</span> uses feature <span class="math inline">\(k\)</span>. Simply put, we sum up all gains of the splits that use feature <span class="math inline">\(k\)</span>. Then, we average over all trees in our ensemble to get the feature importance of feature <span class="math inline">\(k\)</span></p>
<p><span class="math display">\[R_k = \frac{1}{B}\sum_{b=1}^{B} R_k(b).\]</span></p>
<p>Note that the resulting <span class="math inline">\(R_k\)</span> are sometimes normalized such that the maximum value is 100. This means that the most important feature has a feature importance of 100 and all other features are scaled accordingly. Note that feature importance can in principle also be computed for a single decision tree.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note that feature importance tends to favor continuous variables and variables with many categories (<a href="https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html">for an example see here</a>). As an alternative, one can use <strong>permutation importance</strong> which is a model-agnostic way to compute the importance of different features. The idea is to shuffle the values of a feature in the test data set and see how much the model performance decreases. The more the performance decreases, the more important the feature is.</p>
</div>
</div>
</section>
<section id="python-implementation" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="python-implementation"><span class="header-section-number">3.8</span> Python Implementation</h2>
<div class="quarto-embed-nb-cell" data-notebook="/Users/joel/Dropbox (Privat)/Studium/CEMFI/PhD/TA/Data Science for Diploma in Banking Supervision/Local/Lecture Notes/notebooks/decision_trees.ipynb" data-notebook-title="Load the data" data-notebook-cellid="cell-0">
<p>Let’s have a look at how to implement a decision tree in Python. Again, we need to first import the required packages and load the data</p>
<div id="cell-1" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:10:00.323278Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:10:00.322950Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:10:02.906354Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:10:02.905676Z&quot;}" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler, MinMaxScaler</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, plot_tree</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBClassifier</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, accuracy_score, roc_auc_score, recall_score, precision_score, roc_curve</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> permutation_importance</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">'display.max_columns'</span>, <span class="dv">50</span>) <span class="co"># Display up to 50 columns</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data/card_transdata.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This is the <strong>dataset of credit card transactions</strong> from <a href="https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud/data">Kaggle.com</a> which we have used before. Recall that the target variable <span class="math inline">\(y\)</span> is <code>fraud</code>, which indicates whether the transaction is fraudulent or not. The other variables are the features <span class="math inline">\(x\)</span> of the transactions.</p>
<div id="cell-3" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:10:02.909571Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:10:02.909312Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:10:02.930848Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:10:02.930224Z&quot;}" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df.head(<span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">distance_from_home</th>
<th data-quarto-table-cell-role="th">distance_from_last_transaction</th>
<th data-quarto-table-cell-role="th">ratio_to_median_purchase_price</th>
<th data-quarto-table-cell-role="th">repeat_retailer</th>
<th data-quarto-table-cell-role="th">used_chip</th>
<th data-quarto-table-cell-role="th">used_pin_number</th>
<th data-quarto-table-cell-role="th">online_order</th>
<th data-quarto-table-cell-role="th">fraud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>57.877857</td>
<td>0.311140</td>
<td>1.945940</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>10.829943</td>
<td>0.175592</td>
<td>1.294219</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>5.091079</td>
<td>0.805153</td>
<td>0.427715</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>2.247564</td>
<td>5.600044</td>
<td>0.362663</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>44.190936</td>
<td>0.566486</td>
<td>2.222767</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>5.586408</td>
<td>13.261073</td>
<td>0.064768</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>3.724019</td>
<td>0.956838</td>
<td>0.278465</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>4.848247</td>
<td>0.320735</td>
<td>1.273050</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>0.876632</td>
<td>2.503609</td>
<td>1.516999</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>8.839047</td>
<td>2.970512</td>
<td>2.361683</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>14.263530</td>
<td>0.158758</td>
<td>1.136102</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>13.592368</td>
<td>0.240540</td>
<td>1.370330</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12</td>
<td>765.282559</td>
<td>0.371562</td>
<td>0.551245</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">13</td>
<td>2.131956</td>
<td>56.372401</td>
<td>6.358667</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>13.955972</td>
<td>0.271522</td>
<td>2.798901</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">15</td>
<td>179.665148</td>
<td>0.120920</td>
<td>0.535640</td>
<td>1.0</td>
<td>1.0</td>
<td>1.0</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">16</td>
<td>114.519789</td>
<td>0.707003</td>
<td>0.516990</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">17</td>
<td>3.589649</td>
<td>6.247458</td>
<td>1.846451</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">18</td>
<td>11.085152</td>
<td>34.661351</td>
<td>2.530758</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">19</td>
<td>6.194671</td>
<td>1.142014</td>
<td>0.307217</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div id="cell-4" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:10:02.965442Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:10:02.965157Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:10:03.221288Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:10:03.220719Z&quot;}" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">distance_from_home</th>
<th data-quarto-table-cell-role="th">distance_from_last_transaction</th>
<th data-quarto-table-cell-role="th">ratio_to_median_purchase_price</th>
<th data-quarto-table-cell-role="th">repeat_retailer</th>
<th data-quarto-table-cell-role="th">used_chip</th>
<th data-quarto-table-cell-role="th">used_pin_number</th>
<th data-quarto-table-cell-role="th">online_order</th>
<th data-quarto-table-cell-role="th">fraud</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>1000000.000000</td>
<td>1000000.000000</td>
<td>1000000.000000</td>
<td>1000000.000000</td>
<td>1000000.000000</td>
<td>1000000.000000</td>
<td>1000000.000000</td>
<td>1000000.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>26.628792</td>
<td>5.036519</td>
<td>1.824182</td>
<td>0.881536</td>
<td>0.350399</td>
<td>0.100608</td>
<td>0.650552</td>
<td>0.087403</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>65.390784</td>
<td>25.843093</td>
<td>2.799589</td>
<td>0.323157</td>
<td>0.477095</td>
<td>0.300809</td>
<td>0.476796</td>
<td>0.282425</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>0.004874</td>
<td>0.000118</td>
<td>0.004399</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>3.878008</td>
<td>0.296671</td>
<td>0.475673</td>
<td>1.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>9.967760</td>
<td>0.998650</td>
<td>0.997717</td>
<td>1.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>25.743985</td>
<td>3.355748</td>
<td>2.096370</td>
<td>1.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>10632.723672</td>
<td>11851.104565</td>
<td>267.802942</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div id="cell-5" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:10:03.224262Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:10:03.224026Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:10:03.241214Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:10:03.240613Z&quot;}" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 1000000 entries, 0 to 999999
Data columns (total 8 columns):
 #   Column                          Non-Null Count    Dtype  
---  ------                          --------------    -----  
 0   distance_from_home              1000000 non-null  float64
 1   distance_from_last_transaction  1000000 non-null  float64
 2   ratio_to_median_purchase_price  1000000 non-null  float64
 3   repeat_retailer                 1000000 non-null  float64
 4   used_chip                       1000000 non-null  float64
 5   used_pin_number                 1000000 non-null  float64
 6   online_order                    1000000 non-null  float64
 7   fraud                           1000000 non-null  float64
dtypes: float64(8)
memory usage: 61.0 MB</code></pre>
</div>
</div>
<section id="data-preprocessing" class="level3" data-number="3.8.1">
<h3 data-number="3.8.1" class="anchored" data-anchor-id="data-preprocessing"><span class="header-section-number">3.8.1</span> Data Preprocessing</h3>
<p>Since we have already explored the dataset in the previous notebook, we can skip that part and move directly to the data preprocessing.</p>
<p>We will again split the data into training and test sets using the <code>train_test_split</code> function</p>
<div id="cell-7" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:10:03.244378Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:10:03.244138Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:10:03.619666Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:10:03.618438Z&quot;}" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">'fraud'</span>, axis<span class="op">=</span><span class="dv">1</span>) <span class="co"># All variables except `fraud`</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'fraud'</span>] <span class="co"># Only our fraud variables</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, stratify<span class="op">=</span>y, test_size <span class="op">=</span> <span class="fl">0.3</span>, random_state <span class="op">=</span> <span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then we can do the feature scaling to ensure our non-binary variables have mean zero and variance 1</p>
<div id="cell-9" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:10:03.623495Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:10:03.623187Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:10:03.677314Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:10:03.676525Z&quot;}" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> scale_features(scaler, df, col_names, only_transform<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract the features we want to scale</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    features <span class="op">=</span> df[col_names] </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit the scaler to the features and transform them</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> only_transform:</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        features <span class="op">=</span> scaler.transform(features.values)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        features <span class="op">=</span> scaler.fit_transform(features.values)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Replace the original features with the scaled features</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    df[col_names] <span class="op">=</span> features</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>col_names <span class="op">=</span> [<span class="st">'distance_from_home'</span>, <span class="st">'distance_from_last_transaction'</span>, <span class="st">'ratio_to_median_purchase_price'</span>] </span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler() </span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>scale_features(scaler, X_train, col_names)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>scale_features(scaler, X_test, col_names, only_transform<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="implementing-a-decision-tree-classifier" class="level3" data-number="3.8.2">
<h3 data-number="3.8.2" class="anchored" data-anchor-id="implementing-a-decision-tree-classifier"><span class="header-section-number">3.8.2</span> Implementing a Decision Tree Classifier</h3>
<p>We can now implement a decision tree model using the <code>DecisionTreeClassifier</code> class from the <code>sklearn.tree</code> module. Fitting the model to the data is almost the same as when we used logistic regression</p>
<div id="cell-11" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:10:03.681116Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:10:03.680813Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:10:05.075611Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:10:05.074940Z&quot;}" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>clf_dt <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">0</span>).fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can visualize the tree using the <code>plot_tree</code> function from the <code>sklearn.tree</code> module</p>
<div id="cell-13" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:10:05.078722Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:10:05.078466Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:10:06.612414Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:10:06.611784Z&quot;}" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>plot_tree(clf_dt, filled<span class="op">=</span><span class="va">True</span>, feature_names <span class="op">=</span> X_train.columns.to_list())</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/notebooks-decision_trees-cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The tree is quite large and it’s difficult to see details. Let’s only look at the first level of the tree</p>
<div id="cell-15" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:10:06.615403Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:10:06.615160Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:10:06.794988Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:10:06.794198Z&quot;}" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>plot_tree(clf_dt, max_depth<span class="op">=</span><span class="dv">1</span>, filled<span class="op">=</span><span class="va">True</span>, feature_names <span class="op">=</span> X_train.columns.to_list(), fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/notebooks-decision_trees-cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Recall from the data exploration that <code>ratio_to_median_purchase_price</code> was highly correlated with fraud. The decision tree model seems to have picked up on this as well since the first split is based on this variable. Also, note that the order in which the variables are split can differ between different branches of the tree.</p>
<p>We can also make predictions using the model and evaluate its performance using the same functions as before</p>
<div id="cell-17" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:10:06.798209Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:10:06.798003Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:10:07.162081Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:10:07.161358Z&quot;}" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>y_pred_dt <span class="op">=</span> clf_dt.predict(X_test)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>y_proba_dt <span class="op">=</span> clf_dt.predict_proba(X_test)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, y_pred_dt)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Precision: </span><span class="sc">{</span>precision_score(y_test, y_pred_dt)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Recall: </span><span class="sc">{</span>recall_score(y_test, y_pred_dt)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ROC AUC: </span><span class="sc">{</span>roc_auc_score(y_test, y_proba_dt[:, <span class="dv">1</span>])<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.9999833333333333
Precision: 0.9999237223493517
Recall: 0.999885587887571
ROC AUC: 0.999939141362689</code></pre>
</div>
</div>
<p>The decision tree performs substantially better than the logistic regression. The ROC AUC score is much closer to the maximum value of 1 and we have an almost perfect classifier</p>
<div id="cell-19" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:10:07.165118Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:10:07.164869Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:10:07.345786Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:10:07.345271Z&quot;}" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the ROC curve</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thresholds <span class="op">=</span> roc_curve(y_test, y_proba_dt[:, <span class="dv">1</span>])</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the ROC curve</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr, tpr)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], linestyle<span class="op">=</span><span class="st">'--'</span>, color<span class="op">=</span><span class="st">'grey'</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'False Positive Rate (FPR)'</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Positive Rate (TPR)'</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'ROC Curve'</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/notebooks-decision_trees-cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Let’s also check the confusion matrix to see where we still make mistakes</p>
<div id="cell-21" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:10:07.349189Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:10:07.348892Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:10:07.686410Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:10:07.685529Z&quot;}" data-execution_count="12">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>conf_mat <span class="op">=</span> confusion_matrix(y_test, y_pred_dt, labels<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">0</span>]).transpose() <span class="co"># Transpose the sklearn confusion matrix to match the convention in the lecture</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>sns.heatmap(conf_mat, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, fmt<span class="op">=</span><span class="st">'g'</span>, xticklabels<span class="op">=</span>[<span class="st">'Fraud'</span>, <span class="st">'No Fraud'</span>], yticklabels<span class="op">=</span>[<span class="st">'Fraud'</span>, <span class="st">'No Fraud'</span>])</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Actual"</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Predicted"</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/notebooks-decision_trees-cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>There are only 3 false negatives, i.e., fraudulent transactions that we did not detect. There are also 2 false positives, i.e., “false alarms”, where non-fraudulent transactions were classified as fraudulent. The decision tree classifier is almost perfect which is a bit suspicious. We might have been lucky in the sense that the training and test sets were split in a way that the model performs very well. We should not expect this to be the case in general. It might be better to use cross-validation to get a more reliable estimate of the model’s performance.</p>
</section>
<section id="implementing-a-random-forest-classifier" class="level3" data-number="3.8.3">
<h3 data-number="3.8.3" class="anchored" data-anchor-id="implementing-a-random-forest-classifier"><span class="header-section-number">3.8.3</span> Implementing a Random Forest Classifier</h3>
<p>We can also implement a random forest model using the <code>RandomForestClassifier</code> class from the <code>sklearn.ensemble</code> module. Fitting the model to the data is almost the same as when we used logistic regression and decision trees</p>
<div id="cell-23" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:10:07.690254Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:10:07.690013Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:11:10.267786Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:11:10.267180Z&quot;}" data-execution_count="13">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>clf_rf <span class="op">=</span> RandomForestClassifier(random_state <span class="op">=</span> <span class="dv">0</span>).fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that it takes a bit longer to train the Random Forest since we have to train many trees (the default setting is 100). We can also make predictions using the model and evaluate its performance using the same functions as before</p>
<div id="cell-25" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:11:10.271284Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:11:10.271026Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:11:13.314017Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:11:13.313240Z&quot;}" data-execution_count="14">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>y_pred_rf <span class="op">=</span> clf_rf.predict(X_test)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>y_proba_rf <span class="op">=</span> clf_rf.predict_proba(X_test)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, y_pred_rf)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Precision: </span><span class="sc">{</span>precision_score(y_test, y_pred_rf)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Recall: </span><span class="sc">{</span>recall_score(y_test, y_pred_rf)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ROC AUC: </span><span class="sc">{</span>roc_auc_score(y_test, y_proba_rf[:, <span class="dv">1</span>])<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.9999833333333333
Precision: 1.0
Recall: 0.9998093131459517
ROC AUC: 0.9999999993035008</code></pre>
</div>
</div>
<p>As expected, the Random Forest performs better than the Decision Tree in the metrics we have used. Now, let’s also check the confusion matrix to see where we still make mistakes</p>
<div id="cell-27" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:11:13.317155Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:11:13.316877Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:11:13.631584Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:11:13.630614Z&quot;}" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>conf_mat <span class="op">=</span> confusion_matrix(y_test, y_pred_rf, labels<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">0</span>]).transpose() <span class="co"># Transpose the sklearn confusion matrix to match the convention in the lecture</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>sns.heatmap(conf_mat, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, fmt<span class="op">=</span><span class="st">'g'</span>, xticklabels<span class="op">=</span>[<span class="st">'Fraud'</span>, <span class="st">'No Fraud'</span>], yticklabels<span class="op">=</span>[<span class="st">'Fraud'</span>, <span class="st">'No Fraud'</span>])</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Actual"</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Predicted"</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/notebooks-decision_trees-cell-16-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>There are still some false negatives, but the number of false positives has decreased compared to the Decision Tree model.</p>
</section>
<section id="implementing-a-xgboost-classifier" class="level3" data-number="3.8.4">
<h3 data-number="3.8.4" class="anchored" data-anchor-id="implementing-a-xgboost-classifier"><span class="header-section-number">3.8.4</span> Implementing a XGBoost Classifier</h3>
<p>Let’s also have a look at the XGBoost classifier. We can implement the model using the <code>XGBClassifier</code> class from the <code>xgboost</code> package. Fitting the model to the data is almost the same as when we used logistic regression, decision trees, and random forests, even though it is not part of the <code>sklearn</code> package. This is because the <code>xgboost</code> package is designed to work well with the <code>sklearn</code> package. Let’s fit the model to the data</p>
<div id="cell-29" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:11:13.634989Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:11:13.634755Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:11:15.334186Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:11:15.333422Z&quot;}" data-execution_count="16">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>clf_xgb <span class="op">=</span> XGBClassifier(random_state <span class="op">=</span> <span class="dv">0</span>).fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-30" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:11:15.338042Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:11:15.337764Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:11:15.853483Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:11:15.852770Z&quot;}" data-execution_count="17">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>y_pred_xgb <span class="op">=</span> clf_xgb.predict(X_test)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>y_proba_xgb <span class="op">=</span> clf_xgb.predict_proba(X_test)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy: </span><span class="sc">{</span>accuracy_score(y_test, y_pred_xgb)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Precision: </span><span class="sc">{</span>precision_score(y_test, y_pred_xgb)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Recall: </span><span class="sc">{</span>recall_score(y_test, y_pred_xgb)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ROC AUC: </span><span class="sc">{</span>roc_auc_score(y_test, y_proba_xgb[:, <span class="dv">1</span>])<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.9983366666666667
Precision: 0.9893835616438356
Recall: 0.9916097784218756
ROC AUC: 0.999973496046352</code></pre>
</div>
</div>
<p>Let’s also check the confusion matrix to see where we still make mistakes</p>
<div id="cell-32" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:11:15.856535Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:11:15.856307Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:11:16.141828Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:11:16.141059Z&quot;}" data-execution_count="18">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>conf_mat <span class="op">=</span> confusion_matrix(y_test, y_pred_xgb, labels<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">0</span>]).transpose() <span class="co"># Transpose the sklearn confusion matrix to match the convention in the lecture</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>sns.heatmap(conf_mat, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, fmt<span class="op">=</span><span class="st">'g'</span>, xticklabels<span class="op">=</span>[<span class="st">'Fraud'</span>, <span class="st">'No Fraud'</span>], yticklabels<span class="op">=</span>[<span class="st">'Fraud'</span>, <span class="st">'No Fraud'</span>])</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Actual"</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Predicted"</span>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/notebooks-decision_trees-cell-19-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The XGBoost model seems to perform a bit worse than the Random Forest model. There are more false negatives and false positives. However, the model is still very good at detecting fraudulent transactions and has a high ROC AUC score. Adjusting the hyperparameters of the model might improve its performance.</p>
</section>
<section id="feature-importance" class="level3" data-number="3.8.5">
<h3 data-number="3.8.5" class="anchored" data-anchor-id="feature-importance"><span class="header-section-number">3.8.5</span> Feature Importance</h3>
<p>We can also look at the feature importance of each model. The feature importance is a measure of how much each feature contributes to the model’s predictions. Let’s start with the Decision Tree model</p>
<div id="cell-34" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:11:16.145094Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:11:16.144782Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:11:16.284578Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:11:16.283624Z&quot;}" data-execution_count="19">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame with the feature importance</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>df_feature_importance_dt <span class="op">=</span> pd.DataFrame({<span class="st">'Feature'</span>: X_train.columns, <span class="st">'Importance'</span>: clf_dt.feature_importances_})</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>df_feature_importance_dt <span class="op">=</span> df_feature_importance_dt.sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the feature importance</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>plt.barh(df_feature_importance_dt[<span class="st">'Feature'</span>], df_feature_importance_dt[<span class="st">'Importance'</span>])</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Feature'</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importance - Decision Tree'</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/notebooks-decision_trees-cell-20-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This shows that the <code>ratio_to_median_purchase_price</code> is the most important feature for determining whether a transaction is fraudulent or not. Whether a transaction is online, is important as well.</p>
<p>Let’s also look at the feature importance of the Random Forest model</p>
<div id="cell-36" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:11:16.287525Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:11:16.287323Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:11:16.420191Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:11:16.419399Z&quot;}" data-execution_count="20">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame with the feature importance</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>df_feature_importance_rf <span class="op">=</span> pd.DataFrame({<span class="st">'Feature'</span>: X_train.columns, <span class="st">'Importance'</span>: clf_rf.feature_importances_})</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>df_feature_importance_rf <span class="op">=</span> df_feature_importance_rf.sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the feature importance</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>plt.barh(df_feature_importance_rf[<span class="st">'Feature'</span>], df_feature_importance_rf[<span class="st">'Importance'</span>])</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Feature'</span>)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importance - Random Forest'</span>)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/notebooks-decision_trees-cell-21-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Somewhat surprisingly, XGBoost seems to have picked up on different features than the Decision Tree and Random Forest models. The most important feature is <code>online_order</code>, followed by <code>ratio_to_median_purchase_price</code> as you can see from the plot below</p>
<div id="cell-38" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:11:16.423834Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:11:16.423584Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:11:16.562547Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:11:16.561636Z&quot;}" data-execution_count="21">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame with the feature importance</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>df_feature_importance_xgb <span class="op">=</span> pd.DataFrame({<span class="st">'Feature'</span>: X_train.columns, <span class="st">'Importance'</span>: clf_xgb.feature_importances_})</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>df_feature_importance_xgb <span class="op">=</span> df_feature_importance_xgb.sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the feature importance</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>plt.barh(df_feature_importance_xgb[<span class="st">'Feature'</span>], df_feature_importance_xgb[<span class="st">'Importance'</span>])</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance'</span>)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Feature'</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importance - XGBoost'</span>)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/notebooks-decision_trees-cell-22-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="permuation-importance" class="level3" data-number="3.8.6">
<h3 data-number="3.8.6" class="anchored" data-anchor-id="permuation-importance"><span class="header-section-number">3.8.6</span> Permuation Importance</h3>
<p>We can also look at the permutation importance of each model. The permutation importance is a measure of how much each feature contributes to the model’s predictions. The permutation importance is calculated by permuting the values of each feature and measuring how much the model’s performance decreases. Let’s start with the Decision Tree model</p>
<div id="cell-40" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:11:16.565814Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:11:16.565619Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:11:21.334813Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:11:21.334196Z&quot;}" data-execution_count="22">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the permutation importance</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>result_dt <span class="op">=</span> permutation_importance(clf_dt, X_test, y_test, n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame with the feature importance</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>df_permutation_importance_dt <span class="op">=</span> pd.DataFrame({<span class="st">'Feature'</span>: X_train.columns, <span class="st">'Importance'</span>: result_dt.importances_mean})</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>df_permutation_importance_dt <span class="op">=</span> df_permutation_importance_dt.sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the feature importance</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>plt.barh(df_permutation_importance_dt[<span class="st">'Feature'</span>], df_permutation_importance_dt[<span class="st">'Importance'</span>])</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Accuracy Decrease'</span>)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Feature'</span>)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Permutation Importance - Decision Tree'</span>)</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/notebooks-decision_trees-cell-23-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Let’s also look at the permutation importance of the Random Forest model</p>
<div id="cell-42" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:11:21.338786Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:11:21.338565Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:13:05.015056Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:13:05.014407Z&quot;}" data-execution_count="23">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the permutation importance</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>result_rf <span class="op">=</span> permutation_importance(clf_rf, X_test, y_test, n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame with the feature importance</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>df_permutation_importance_rf <span class="op">=</span> pd.DataFrame({<span class="st">'Feature'</span>: X_train.columns, <span class="st">'Importance'</span>: result_rf.importances_mean})</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>df_permutation_importance_rf <span class="op">=</span> df_permutation_importance_rf.sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the feature importance</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>plt.barh(df_permutation_importance_rf[<span class="st">'Feature'</span>], df_permutation_importance_rf[<span class="st">'Importance'</span>])</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Accuracy Decrease'</span>)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Feature'</span>)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Permutation Importance - Random Forest'</span>)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/notebooks-decision_trees-cell-24-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Let’s also look at the permutation importance of the XGBoost model</p>
<div id="cell-44" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-05-13T13:13:05.018343Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-05-13T13:13:05.018088Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-13T13:13:13.176046Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-13T13:13:13.175345Z&quot;}" data-execution_count="24">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the permutation importance</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>result_xgb <span class="op">=</span> permutation_importance(clf_xgb, X_test, y_test, n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame with the feature importance</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>df_permutation_importance_xgb <span class="op">=</span> pd.DataFrame({<span class="st">'Feature'</span>: X_train.columns, <span class="st">'Importance'</span>: result_xgb.importances_mean})</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>df_permutation_importance_xgb <span class="op">=</span> df_permutation_importance_xgb.sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the feature importance</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>plt.barh(df_permutation_importance_xgb[<span class="st">'Feature'</span>], df_permutation_importance_xgb[<span class="st">'Importance'</span>])</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Accuracy Decrease'</span>)</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Feature'</span>)</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Permutation Importance - XGBoost'</span>)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="decisiontrees_files/figure-html/notebooks-decision_trees-cell-25-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Here the results for the three models are quite similar. The most important feature is <code>ratio_to_median_purchase_price</code>, followed by <code>online_order</code>.</p>
</section>
<section id="conclusions" class="level3" data-number="3.8.7">
<h3 data-number="3.8.7" class="anchored" data-anchor-id="conclusions"><span class="header-section-number">3.8.7</span> Conclusions</h3>
<p>In this notebook, we have seen how to implement decision trees, random forests, and XGBoost classifiers in Python. We have also seen how to evaluate the performance of these models using metrics such as accuracy, precision, recall, and ROC AUC. We have seen that the Random Forest and XGBoost models perform better than the Decision Tree model. Furthermore, we looked at the feature and permutation importance of each model to see which features are most important for determining whether a transaction is fraudulent or not.</p>
</section>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Hastie2009" class="csl-entry" role="listitem">
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. <em><span class="nocase">The Elements of Statistical Learning - Data Mining, Inference, and Prediction</span></em>. Second Edition. Springer.
</div>
<div id="ref-Murphy2022" class="csl-entry" role="listitem">
Murphy, Kevin P. 2022. <em><span>Probabilistic Machine Learning: An Introduction</span></em>. MIT Press. <a href="https://probml.github.io/pml-book/book1.html">https://probml.github.io/pml-book/book1.html</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Note to handle missing input data one can use “backup” variables that are correlated with the variable of interest and can be used to make a split whenever the data is missing. Such splits are called <strong>surrogate splits</strong>. In the case of categorical variables, one can also use a separate category for missing values.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./basics.html" class="pagination-link" aria-label="Basic Concepts">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Basic Concepts</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./neuralnetworks.html" class="pagination-link" aria-label="Neural Networks">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Neural Networks</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>